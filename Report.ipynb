{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d872060",
   "metadata": {},
   "source": [
    "### CS 421 PROJECT\n",
    "\n",
    "Team members:\n",
    "- Emmanuel Oh\n",
    "- Lee Shiying\n",
    "- Megan Tan\n",
    "- Sheffield Lok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCHES_DIR = 'batches/'\n",
    "PREDS_DIR = 'predictions/'\n",
    "\n",
    "# Load data from previous batches as training sets\n",
    "batch1=np.load(BATCHES_DIR+\"first_batch.npz\")\n",
    "batch2=np.load(BATCHES_DIR+\"second_batch_with_labels.npz\")\n",
    "batch3=np.load(BATCHES_DIR+\"third_batch_with_labels.npz\")\n",
    "batch4=np.load(BATCHES_DIR+\"fourth_batch_with_labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ea779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert loaded data into pd.DataFrame objects\n",
    "X1=pd.DataFrame(batch1[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y1=pd.DataFrame(batch1[\"y\"], columns=[\"user\", \"label\"])\n",
    "X2=pd.DataFrame(batch2[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y2=pd.DataFrame(batch2[\"y\"], columns=[\"user\", \"label\"])\n",
    "X3=pd.DataFrame(batch3[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y3=pd.DataFrame(batch3[\"y\"], columns=[\"user\", \"label\"])\n",
    "X4=pd.DataFrame(batch4[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y4=pd.DataFrame(batch4[\"y\"], columns=[\"user\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57e134",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(t: str, X: pd.DataFrame):\n",
    "    real = X.loc[X['label'] == 0]\n",
    "    fake = X.loc[X['label'] == 1]\n",
    "    r_real: pd.Series = real['rating']\n",
    "    r_fake: pd.Series = fake['rating']\n",
    "    metrics = pd.DataFrame(\n",
    "        {\n",
    "            'Status': ['Real', 'Fake'],\n",
    "            'Count': [len(r_real), len(r_fake)],\n",
    "            'Mean': [r_real.mean(), r_fake.mean()],\n",
    "            'Median': [r_real.median(), r_fake.median()],\n",
    "            'Std': [r_real.std(), r_fake.std()],\n",
    "            'Min': [r_real.min(), r_fake.min()],\n",
    "            'Max': [r_real.max(), r_fake.max()]\n",
    "        }\n",
    "    )\n",
    "    print(f'------------------------------------{t}------------------------------------')\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    bins = [0,1,2,3,4,5,6]\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].hist(r_real, bins)\n",
    "    axs[1].hist(r_fake, bins)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee263c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 'Batch 1'\n",
    "X1_labeled: pd.DataFrame = pd.merge(X1, y1)\n",
    "t2 = 'Batch 2'\n",
    "X2_labeled: pd.DataFrame = pd.merge(X2, y2)\n",
    "t3 = 'Batch 3'\n",
    "X3_labeled: pd.DataFrame = pd.merge(X3, y3)\n",
    "t4 = 'Batch 4'\n",
    "X4_labeled: pd.DataFrame = pd.merge(X4, y4)\n",
    "\n",
    "for t, X_labeled in [(t1, X1_labeled), (t2, X2_labeled), (t3, X3_labeled), (t4, X4_labeled)]:\n",
    "    show_metrics(t, X_labeled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0116e2",
   "metadata": {},
   "source": [
    "### Feature engineering, model training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9771a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all previous weeks' batches into a single dataframe each\n",
    "data_X = [X1, X2, X3, X4]\n",
    "data_y = [y1, y2, y3, y4]\n",
    "X = pd.concat(data_X)\n",
    "y = pd.concat(data_y)\n",
    "\n",
    "\n",
    "y.drop('user', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ae7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute useful features for model fitting\n",
    "def get_features(X: pd.DataFrame):\n",
    "  '''Takes in a DataFrame of user-item-rating entries and computes descriptive\n",
    "  features based on each user's collated reviews\n",
    "\n",
    "\n",
    "  Features include:\n",
    "  - Review count\n",
    "  - Total sum of reviews\n",
    "  - Standard error of mean\n",
    "  - Standard deviation\n",
    "  - 25% quantile\n",
    "  - 50% quantile\n",
    "  - 75% quantile\n",
    "  - mean\n",
    "  - median\n",
    "  - max\n",
    "  - min\n",
    "  - mode\n",
    "  \n",
    "\n",
    "  Returns a DataFrame with computed features for each unique user\n",
    "  '''\n",
    "  features = pd.DataFrame(X.groupby('user')['user'].max())\n",
    "  features['count'] = X.groupby('user')['rating'].count()\n",
    "  features['sum'] = X.groupby('user')['rating'].sum()\n",
    "  features['sem'] = X.groupby('user')['rating'].sem()\n",
    "  features['std'] = X.groupby('user')['rating'].std()\n",
    "  features['25%'] = X.groupby('user')['rating'].quantile(0.25)\n",
    "  features['50%'] = X.groupby('user')['rating'].quantile(0.50)\n",
    "  features['75%'] = X.groupby('user')['rating'].quantile(0.75)\n",
    "  features['mean'] = X.groupby('user')['rating'].mean()\n",
    "  features['median'] = X.groupby('user')['rating'].median()\n",
    "  features['max'] = X.groupby('user')['rating'].max()\n",
    "  features['min'] = X.groupby('user')['rating'].min()\n",
    "  features['mode'] = X.groupby('user')['rating'].apply(\n",
    "      lambda x: x.value_counts().index[0]\n",
    "    )\n",
    "  return features\n",
    "\n",
    "\n",
    "X = get_features(X).fillna(0)\n",
    "X.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab08701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Classification/Anomaly Detection methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "\n",
    "\n",
    "# Model evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, \\\n",
    "  recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "# Model-fitting\n",
    "########### Logistic Regression ##########\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, np.ravel(y_train, order='C'))\n",
    "\n",
    "\n",
    "########### K-Means ##########\n",
    "# Set n_clusters to 1, as legitimate users should cluster around 1 distribution\n",
    "N_Kmeans = 1\n",
    "kmeans = KMeans(n_clusters=N_Kmeans, init='k-means++', max_iter=50, random_state=0)\n",
    "kmeans.fit(X)\n",
    "\n",
    "    \n",
    "########## Gaussian Mixture ##########\n",
    "# Set n_components to 1 as we treat normal users as a single cluster,\n",
    "# with fake users as anomalies\n",
    "N_GMix = 1\n",
    "gm = GaussianMixture(n_components=N_GMix, random_state=0, covariance_type=\"full\")\n",
    "gm.fit(X)\n",
    "\n",
    "\n",
    "########### Isolation Forest ##########\n",
    "il=IsolationForest(n_estimators=500)\n",
    "il.fit(X)\n",
    "\n",
    "\n",
    "########## Random Forest ##########\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X, np.ravel(y_train, order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "\n",
    "scaler=[RobustScaler() for _ in range(N_Kmeans)]\n",
    "dists_train, centres_train = kmeans.transform(X), kmeans.predict(X)\n",
    "distnear_train = dists_train[range(centres_train.shape[0]), centres_train]\n",
    "dists_test, centres_test = kmeans.transform(X_test), kmeans.predict(X_test)\n",
    "distnear_test = dists_test[range(centres_test.shape[0]), centres_test]\n",
    "for i in range(N_Kmeans):\n",
    "    scaler[i].fit(distnear_train[centres_train==i].reshape(-1,1))\n",
    "for i in range(N_Kmeans):\n",
    "    distnear_test[centres_test==i] = scaler[i].transform(\n",
    "        distnear_test[centres_test==i].reshape(-1,1)\n",
    "    ).reshape(-1)\n",
    "\n",
    "\n",
    "# For Kmeans and GM, normalize values to lie between 0-1, and take those \n",
    "# as predictions\n",
    "def normalize(X):\n",
    "  '''Normalizes values `i` in an array `X` to 0-1 by computing \n",
    "  `(i - min(x)) / (max(x) - min(x))`\n",
    "  '''\n",
    "  dist_min = min(X)\n",
    "  dist_max = max(X)\n",
    "  preds = np.array([(i-dist_min)/(dist_max-dist_min) for i in X])\n",
    "  return preds\n",
    "\n",
    "\n",
    "y_pred_lr = lr.predict_proba(X_test)[:,1]\n",
    "y_pred_km = normalize(distnear_test)\n",
    "y_pred_gm = normalize(-gm.score_samples(X_test))\n",
    "y_pred_il = -il.score_samples(X_test)\n",
    "y_pred_rf = rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y_test['label']\n",
    "y_pred_km_disc = np.round(y_pred_km)\n",
    "\n",
    "\n",
    "print(f\"F1: {f1_score(labels, y_pred_km_disc)}\")\n",
    "print(f\"Precision: {precision_score(labels, y_pred_km_disc)}\")\n",
    "print(f\"Recall: {recall_score(labels, y_pred_km_disc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c079ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(labels, pred):\n",
    "    '''Takes in a set of true labels 0-1 and predictions (probabilistic\n",
    "    or 0-1) and computes key evaluation metrics\n",
    "\n",
    "    - AUC\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "    '''\n",
    "    print(f\"AUC         : {roc_auc_score(labels, pred)}\")\n",
    "    pred_discrete = np.round(pred)\n",
    "    print(f\"Accuracy    : {accuracy_score(labels, pred_discrete)}\")\n",
    "    print(f\"Precision   : {precision_score(labels, pred_discrete)}\")\n",
    "    print(f\"Recall      : {recall_score(labels, pred_discrete)}\")\n",
    "    print(f\"F1          : {f1_score(labels, pred_discrete)}\")\n",
    "\n",
    "\n",
    "labels = y_test['label']\n",
    "print(\"------------Logistic Regression------------\")\n",
    "print_metrics(labels, y_pred_lr)\n",
    "print(\"------------K Means------------------------\")\n",
    "print_metrics(labels, y_pred_km)\n",
    "print(\"------------Gaussian Mixture---------------\")\n",
    "print_metrics(labels, y_pred_gm)\n",
    "print(\"------------Isolation Forest---------------\")\n",
    "print_metrics(labels, y_pred_il)\n",
    "print(\"------------Random Forest------------------\")\n",
    "print_metrics(labels, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions\n",
    "batch_final=np.load(BATCHES_DIR+\"FINAL_batch.npz\")\n",
    "X_final=pd.DataFrame(batch_final[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "X_final_features = get_features(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69226f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Forest classifier\n",
    "y_pred_proba_rf = rf.predict_proba(X_final_features)[:,1]\n",
    "predictions = pd.DataFrame(y_pred_proba_rf, columns=['y_pred'])\n",
    "# Save output\n",
    "np.savez(PREDS_DIR+'predictions_FINAL.npz', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "418913cb93534b0d0cf5f0fefdeb6f7e72048ef16d0da548eb476d106ddc4cf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
