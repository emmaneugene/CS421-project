{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS 421 PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load all previous weeks' data as training sets\n",
    "batch1=np.load(\"first_batch.npz\")\n",
    "batch2=np.load(\"second_batch_with_labels.npz\")\n",
    "batch3=np.load(\"third_batch_with_labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9a6ea779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=pd.DataFrame(batch1[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y1=pd.DataFrame(batch1[\"y\"], columns=[\"user\", \"label\"])\n",
    "X2=pd.DataFrame(batch2[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y2=pd.DataFrame(batch2[\"y\"], columns=[\"user\", \"label\"])\n",
    "X3=pd.DataFrame(batch3[\"X\"], columns=[\"user\", \"item\", \"rating\"])\n",
    "y3=pd.DataFrame(batch3[\"y\"], columns=[\"user\", \"label\"])\n",
    "\n",
    "# Concatenate all previous weeks' batches into a single dataframe each\n",
    "data_X = [X1, X2, X3]\n",
    "data_y = [y1, y2, y3]\n",
    "X = pd.concat(data_X)\n",
    "y = pd.concat(data_y)\n",
    "\n",
    "y.drop('user', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "de1ae7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X: pd.DataFrame):\n",
    "  features = pd.DataFrame(X.groupby('user')['user'].max())\n",
    "  features['count'] = X.groupby('user')['rating'].count()\n",
    "  features['std'] = X.groupby('user')['rating'].std()\n",
    "  features['25%'] = X.groupby('user')['rating'].quantile(0.25)\n",
    "  features['50%'] = X.groupby('user')['rating'].quantile(0.50)\n",
    "  features['75%'] = X.groupby('user')['rating'].quantile(0.75)\n",
    "  \n",
    "  features['mean'] = X.groupby('user')['rating'].mean()\n",
    "  features['median'] = X.groupby('user')['rating'].median()\n",
    "  features['max'] = X.groupby('user')['rating'].max()\n",
    "  features['min'] = X.groupby('user')['rating'].min()\n",
    "  features['mode'] = X.groupby('user')['rating'].apply(lambda x: x.value_counts().index[0])\n",
    "  return features\n",
    "\n",
    "X_features = get_features(X)\n",
    "X_features = X_features.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bab08701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Anomaly detection methods\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d5b524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y, list):\n",
    "    for i in range (len(list)):\n",
    "        print(f\"AUC: {roc_auc_score(y, list[i][1])}\")\n",
    "        print(f\"F1: {f1_score(y, list[i][0])}\")\n",
    "        print(f\"Precision: {precision_score(y4, list[i][0])}\")\n",
    "        print(f\"Recall: {recall_score(y, list[i][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "aaa4cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### AUC SCORES ######################### \n",
      "Isolation Forest: 0.6709034895661778\n",
      "Logistic Regression: 0.9077183158628974\n",
      "KMeans: 0.5311173974540311\n",
      "Gaussian Mixture: 0.6894605801088916\n",
      "Random Forest: 0.925880626223092\n",
      "##############################################################\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "########### Isolation Forest ##########\n",
    "IL=IsolationForest(n_estimators=500)\n",
    "IL.fit(X_train)\n",
    "\n",
    "########### Logistic Regression ##########\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, np.ravel(y_train, order='C'))\n",
    "y_pred_lr = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "########### Kmeans ##########\n",
    "N=4 # 4 seems optimal (i tried 2 to 12 clusters)\n",
    "kmeans = KMeans(n_clusters=N, init='k-means++', max_iter=50, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "scaler=[RobustScaler() for _ in range(N)]\n",
    "distances_train, centres_train = kmeans.transform(X_train), kmeans.predict(X_train)\n",
    "distnear_train = distances_train[range(centres_train.shape[0]), centres_train]\n",
    "distances_test, centres_test = kmeans.transform(X_test), kmeans.predict(X_test)\n",
    "distnear_test = distances_test[range(centres_test.shape[0]), centres_test]\n",
    "\n",
    "for i in range(N):\n",
    "    scaler[i].fit(distnear_train[centres_train==i].reshape(-1,1))\n",
    "for i in range(N):\n",
    "    distnear_test[centres_test==i] = scaler[i].transform(distnear_test[centres_test==i].reshape(-1,1)).reshape(-1)\n",
    "    \n",
    "########## Gaussian Mixture ##########\n",
    "NN = 1\n",
    "gm = GaussianMixture(n_components=NN, random_state=0, covariance_type=\"full\").fit(X_train)\n",
    "y_pred_gm = -gm.score_samples(X_test)\n",
    "\n",
    "########## Random Forest ##########\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, np.ravel(y_train, order='C'))\n",
    "y_pred_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "    \n",
    "# Print AUC scores\n",
    "print(\"######################### AUC SCORES ######################### \")\n",
    "print(\"Isolation Forest:\", roc_auc_score(y_test,-IL.score_samples(X_test)))\n",
    "print(\"Logistic Regression:\", roc_auc_score(y_test,y_pred_lr))\n",
    "print(\"KMeans:\", roc_auc_score(y_test, distnear_test))\n",
    "print(\"Gaussian Mixture:\", roc_auc_score(y_test, y_pred_gm))\n",
    "print(\"Random Forest:\", roc_auc_score(y_test, y_pred_rf))\n",
    "print(\"##############################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "966ee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and predict on fourth batch\n",
    "batch4 = np.load('fourth_batch_with_labels.npz')\n",
    "X4 = pd.DataFrame(batch4['X'], columns=[\"user\", \"item\", \"rating\"])\n",
    "y4 = pd.DataFrame(batch4['y'], columns=[\"user\", \"label\"])  \n",
    "y4.drop(\"user\", axis=1, inplace=True)\n",
    "\n",
    "# Get features on 4th batch\n",
    "X4_features = get_features(X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0d9a0db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Logistic regression evaluation metrics------\n",
      "AUC: 0.83306\n",
      "F1: 0.6284658040665435\n",
      "Precision: 0.7053941908713693\n",
      "Recall: 0.5666666666666667\n",
      "\n",
      "------Random Forest evaluation metrics------\n",
      "AUC: 0.8769883333333334\n",
      "F1: 0.6181015452538632\n",
      "Precision: 0.9150326797385621\n",
      "Recall: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr.fit(X_features, np.ravel(y, order='C'))\n",
    "y_pred_logreg = lr.predict(X4_features)\n",
    "y_pred_proba = lr.predict_proba(X4_features)[::,1]\n",
    "logreg = []\n",
    "list = []\n",
    "logreg.append(y_pred_logreg)\n",
    "logreg.append(y_pred_proba)\n",
    "list.append(logreg)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print(\"------Logistic regression evaluation metrics------\")\n",
    "get_metrics(y4, list)\n",
    "\n",
    "# Random Forest\n",
    "rf.fit(X_features, np.ravel(y, order='C'))\n",
    "y_pred_rf = rf.predict(X4_features)\n",
    "y_pred_proba_rf = rf.predict_proba(X4_features)[:,1]\n",
    "\n",
    "random_forest = []\n",
    "list = []\n",
    "random_forest.append(y_pred_rf)\n",
    "random_forest.append(y_pred_proba_rf)\n",
    "list.append(random_forest)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "print()\n",
    "print(\"------Random Forest evaluation metrics------\")\n",
    "get_metrics(y4, list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "87521247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### AUC SCORES ######################### \n",
      "Isolation Forest: 0.68783\n",
      "Logistic Regression: 0.83306\n",
      "Gaussian Mixture: 0.6846766666666667\n",
      "Random Forest: 0.8769883333333334\n",
      "##############################################################\n"
     ]
    }
   ],
   "source": [
    "### Prediction on 4th batch \n",
    "\n",
    "########### Isolation Forest ##########\n",
    "IL=IsolationForest(n_estimators=500)\n",
    "IL.fit(X_features)\n",
    "\n",
    "########### Logistic Regression ##########\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_features, np.ravel(y, order='C'))\n",
    "y_pred_lr = lr.predict_proba(X4_features)[:,1]\n",
    "\n",
    "########### Kmeans ##########\n",
    "# N=3 # 4 seems optimal (i tried 2 to 12 clusters)\n",
    "# kmeans = KMeans(n_clusters=N, init='k-means++', max_iter=50, random_state=0)\n",
    "# kmeans.fit(X_features)\n",
    "# scaler=[RobustScaler() for _ in range(N)]\n",
    "# distances_train, centres_train = kmeans.transform(X_features), kmeans.predict(X_features)\n",
    "# distnear_train = distances_train[range(centres_train.shape[0]), centres_train]\n",
    "# distances_test, centres_test = kmeans.transform(X4_features), kmeans.predict(X4_features)\n",
    "# distnear_test = distances_test[range(centres_test.shape[0]), centres_test]\n",
    "\n",
    "# for i in range(N):\n",
    "#     scaler[i].fit(distnear_train[centres_train==i].reshape(-1,1))\n",
    "# for i in range(N):\n",
    "#     distnear_test[centres_test==i] = scaler[i].transform(distnear_test[centres_test==i].reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    \n",
    "########## Gaussian Mixture ##########\n",
    "NN = 1\n",
    "gm = GaussianMixture(n_components=NN, random_state=0, covariance_type=\"full\").fit(X_train)\n",
    "y_pred_gm = -gm.score_samples(X4_features)\n",
    "\n",
    "\n",
    "    \n",
    "# Print AUC scores\n",
    "print(\"######################### AUC SCORES ######################### \")\n",
    "print(\"Isolation Forest:\", roc_auc_score(y4,-IL.score_samples(X4_features)))\n",
    "print(\"Logistic Regression:\", roc_auc_score(y4,y_pred_lr))\n",
    "# print(\"KMeans:\", roc_auc_score(y_test, distnear_test))\n",
    "print(\"Gaussian Mixture:\", roc_auc_score(y4, y_pred_gm))\n",
    "print(\"Random Forest:\", roc_auc_score(y4, y_pred_proba_rf))\n",
    "print(\"##############################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c4fc30bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.163783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.894505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.168176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>0.479621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>0.318975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1297</td>\n",
       "      <td>0.322827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1298</td>\n",
       "      <td>0.879626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1299</td>\n",
       "      <td>0.329377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_pred\n",
       "0     0.163783\n",
       "1     0.894505\n",
       "2     0.250268\n",
       "3     0.168176\n",
       "4     0.299802\n",
       "...        ...\n",
       "1295  0.479621\n",
       "1296  0.318975\n",
       "1297  0.322827\n",
       "1298  0.879626\n",
       "1299  0.329377\n",
       "\n",
       "[1300 rows x 1 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(y_pred_proba, columns=['y_pred'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3ca6d6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "1295       0\n",
       "1296       0\n",
       "1297       0\n",
       "1298       1\n",
       "1299       0\n",
       "\n",
       "[1300 rows x 1 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rf = pd.DataFrame(y_pred_rf, columns=['y_pred'])\n",
    "predictions_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "affc2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and predict on final batch\n",
    "batch_final = np.load('FINAL_batch.npz')\n",
    "X_final = pd.DataFrame(batch4['X'], columns=[\"user\", \"item\", \"rating\"])\n",
    "\n",
    "# Get features on final batch\n",
    "X_final_features = get_features(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c6b00a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest for final batch\n",
    "rf.fit(X_features, np.ravel(y, order='C'))\n",
    "y_pred_rf = rf.predict(X_final_features)\n",
    "y_pred_proba_rf = rf.predict_proba(X_final_features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f745d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('W12_predictions_final.npz', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
